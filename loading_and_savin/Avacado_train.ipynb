{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from pickle import dump\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainData(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
      "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
      "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
      "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
      "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
      "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
      "\n",
      "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
      "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
      "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
      "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
      "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
      "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
      "\n",
      "   year  region  \n",
      "0  2015  Albany  \n",
      "1  2015  Albany  \n",
      "2  2015  Albany  \n",
      "3  2015  Albany  \n",
      "4  2015  Albany  \n"
     ]
    }
   ],
   "source": [
    "#read in files\n",
    "file_in = os.getcwd() + \"/avacados/avocado.csv\"\n",
    "df = pd.read_csv(file_in)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['region', 'Date', 'XLarge Bags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0        int64\n",
      "Total Volume    float64\n",
      "4046            float64\n",
      "4225            float64\n",
      "4770            float64\n",
      "Total Bags      float64\n",
      "Small Bags      float64\n",
      "Large Bags      float64\n",
      "type             object\n",
      "year              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(df.head)\n",
    "X = df.iloc[:, df.columns != 'AveragePrice'] #grab first 13 elements for input\n",
    "y = df.loc[:, df.columns == 'AveragePrice'].values   #seperate last element (target values)\n",
    "\n",
    "\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5653269  -0.22480975 -0.80622027 ... -1.02988101 -0.99983562\n",
      "  -1.22128204]\n",
      " [-1.50073001 -0.27912775 -0.95279724 ... -1.02493487 -0.99983562\n",
      "  -1.22128204]\n",
      " [-1.43613312  0.0519082  -0.90024357 ... -1.01669129 -0.99983562\n",
      "  -1.22128204]\n",
      " ...\n",
      " [-0.98395486 -0.74291995 -0.75443101 ... -1.12179684  1.00016441\n",
      "   1.97050371]\n",
      " [-0.91935797 -0.66448171 -0.65333685 ... -1.10469143  1.00016441\n",
      "   1.97050371]\n",
      " [-0.85476108 -0.63162502 -0.39286172 ... -1.16796085  1.00016441\n",
      "   1.97050371]]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "#X = X.apply(le.fit_transform)\n",
    "scaler = StandardScaler()\n",
    "X['type'] = le.fit_transform(X['type'].astype(str))\n",
    "X_train = scaler.fit_transform(X)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data into a tensor of floats\n",
    "train_data = trainData(torch.FloatTensor(X_train),torch.FloatTensor(y))\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "#build model and pass it to device (CPU or GPU)\n",
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_actual):\n",
    "    #print(y_pred, y_actual)\n",
    "    diff = (abs(y_pred - y_actual)/(y_pred + y_actual)).mean()\n",
    "    diff = (1 - diff) * 100\n",
    "    #print(diff)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexro/miniconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Loss: 0.19913\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 001: | Loss: 0.16619\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 002: | Loss: 0.15801\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 003: | Loss: 0.15269\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 004: | Loss: 0.14871\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch 005: | Loss: 0.14468\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch 006: | Loss: 0.14127\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch 007: | Loss: 0.13925\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch 008: | Loss: 0.13717\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch 009: | Loss: 0.13604\n",
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    print(f\"Epoch {e + 1}\\n-------------------------------\")\n",
    "    for features, labels in train_loader:\n",
    "\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        y_pred = model(features)\n",
    "        loss = loss_fn(y_pred, labels.unsqueeze(1))\n",
    "        acc = accuracy(y_pred, labels.unsqueeze(1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e + 0:03}: | Loss: {epoch_loss / len(train_loader):.5f}')\n",
    "\n",
    "print(\"Done Training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1561]], grad_fn=<AddmmBackward>) tensor([[1.3600]])\n"
     ]
    }
   ],
   "source": [
    "print(y_pred, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexro/miniconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NeuralNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "torch.save(model, '/Users/alexro/NERDS/ML_Sessions/avacado_model.pt')\n",
    "# save the value label encoding\n",
    "np.save('/Users/alexro/NERDS/ML_Sessions/encoding.npy', le.classes_)\n",
    "# save the vvalue standard scaler\n",
    "dump(scaler, open('/Users/alexro/NERDS/ML_Sessions/scaler.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexro/NERDS/ML_Sessions\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
