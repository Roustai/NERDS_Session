{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from pickle import dump, load\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cpu\n"
     ]
    }
   ],
   "source": [
    "print(f'running on {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data scaling\n",
    "scaler = load(open('/Users/alexro/NERDS/ML_Sessions/scaler.pkl','rb'))\n",
    "\n",
    "#Load in label encoding\n",
    "le  = LabelEncoder()\n",
    "le.classes_ = np.load('/Users/alexro/NERDS/ML_Sessions/encoding.npy', allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testData(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in model, model must be loaded in after its class is instantiated\n",
    "#otherwise you will get a serialization error\n",
    "model = torch.load('/Users/alexro/NERDS/ML_Sessions/avacado_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  AveragePrice  Total Volume        4046       4225      4770  \\\n",
      "0           0          1.07     417232.18   278048.26   62485.97    714.93   \n",
      "1           1          1.10     454702.00   382900.99   19543.18    522.81   \n",
      "2           2          2.03       1794.39     1069.54     187.76      0.00   \n",
      "3           3          1.38    1975524.70   833904.89  499191.31  10560.99   \n",
      "4           4          1.16    2197763.70  1420318.78  298081.99  25682.97   \n",
      "\n",
      "   Total Bags  Small Bags  Large Bags          type  year  \n",
      "0    75983.02    46290.32    29678.76  conventional  2015  \n",
      "1    51735.02    40505.16    11199.95  conventional  2015  \n",
      "2      537.09      500.00       37.09       organic  2016  \n",
      "3   631867.51   584294.01    29543.77  conventional  2017  \n",
      "4   453679.96   309652.75   143978.69  conventional  2015  \n"
     ]
    }
   ],
   "source": [
    "#read in files\n",
    "file_in = os.getcwd() + \"/avacados/avac_sample.csv\"\n",
    "df = pd.read_csv(file_in)\n",
    "\n",
    "df = df.drop(columns=['region', 'Date', 'XLarge Bags'])\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AveragePrice\n",
      "0          1.07\n",
      "1          1.10\n",
      "2          2.03\n",
      "3          1.38\n",
      "4          1.16\n",
      "5          1.13\n",
      "6          1.13\n",
      "7          1.17\n",
      "8          1.02\n",
      "9          2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexro/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "#print(df.head)\n",
    "X = df.iloc[:, df.columns != 'AveragePrice'] #grab first 13 elements for input\n",
    "y = df.loc[:, df.columns == 'AveragePrice']   #seperate last element (target values)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "X['type'] = le.fit_transform(X['type'].astype(str))\n",
    "X_test = scaler.fit_transform(X)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data into a tensor of floats\n",
    "test_data = testData(torch.FloatTensor(X_test),torch.FloatTensor(y.values))\n",
    "dataloader = DataLoader(dataset=test_data, batch_size=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted model generated 1.24017\t actual was 1.17 \t difference was 0.07017\n",
      "The predicted model generated 2.23422\t actual was 2.39 \t difference was -0.15578\n",
      "The predicted model generated 1.00428\t actual was 1.16 \t difference was -0.15572\n",
      "The predicted model generated 0.66079\t actual was 1.02 \t difference was -0.35921\n",
      "The predicted model generated 1.4121\t actual was 1.13 \t difference was 0.2821\n",
      "The predicted model generated 1.30482\t actual was 1.38 \t difference was -0.07518\n",
      "The predicted model generated 1.15614\t actual was 1.07 \t difference was 0.08614\n",
      "The predicted model generated 1.21759\t actual was 1.13 \t difference was 0.08759\n",
      "The predicted model generated 1.17116\t actual was 1.1 \t difference was 0.07116\n",
      "The predicted model generated 2.49143\t actual was 2.03 \t difference was 0.46143\n"
     ]
    }
   ],
   "source": [
    "size = len(dataloader.dataset)\n",
    "num_batches = len(dataloader)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        print(f'''The predicted model generated {round(pred.item(),5)}\\t actual was {round(y.item(), 5)} \\t difference was {round((pred-y).item(),5)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
